{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNIT TESTING\n",
    "## Introduction to Testing\n",
    "When working with Python, or any programming language, there is a lot that can go wrong with our code. There are syntax errors and exceptions, but there are also mistakes in the program logic which cause it to behave in unexpected ways.\n",
    "\n",
    "For these reasons, testing is crucial to creating quality software. The goal of testing isn’t just to find bugs but to find them quickly. Leaving bugs unfound and unresolved can lead to massive consequences in the real world. Take a look at some of the most infamous bugs that have ever occurred in software.\n",
    "\n",
    "Don’t worry though - by following some common practices and using the tools built into Python, we can start creating quality tests in no time. To dive in, first, let’s talk about the different types of testing styles that exist.\n",
    "\n",
    "The world of testing can generally be divided into two categories:\n",
    "\n",
    "- Manual Testing:\n",
    "    - With manual testing, a physical person interacts with software much as a user would. In fact, we have been manually testing our code any time we run it and observe the results!\n",
    "- Automated Testing:\n",
    "    - With automated testing, tests are performed with code. Generally, automated testing is faster and less prone to human error.\n",
    "\n",
    "\n",
    "In this lesson, we’ll be diving into the world of testing. For most of the exercises, let’s imagine we’ve been hired to create tests for a new airline company called Small World Air. Before we start writing automated tests, let’s do some manual testing and see what kind of shape their software is in.\n",
    "\n",
    "### Instructions\n",
    "#### 1. Small World Air provided us access to a program that displays the flight status for all current flights. Manually test the code by running it and observing the output.\n",
    "\n",
    "#### 2. Uh oh, we hit a TypeError! Can you spot and fix the error? Manually test your bug fix by running the program again.\n",
    "\n",
    "\n",
    "<b>Hint</b><br>\n",
    "Integers cannot be concatenated with strings. Check out line 11!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_statuses = {\n",
    "  903: 'Departed',\n",
    "  834: 'Boarding',\n",
    "  359: 'Delayed',\n",
    "  128: 'On time',\n",
    "  385: 'On time',\n",
    "}\n",
    "\n",
    "print('***Small World Air Flight Information***')\n",
    "for flight, status in flight_statuses.items():\n",
    "  print('Flight ' + str(flight) + ' status: ' + status)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The assert Statement\n",
    "While the previous example was simple to test, most code will be much more complex. It would be very tedious to have to perform these tests manually. Our time would be better spent writing automated tests.\n",
    "\n",
    "Luckily, Python provides an easy way to perform simple tests in our code - the assert statement. An assert statement can be used to test that a condition is met. If the condition evaluates to False, an AssertionError is raised with an optional error message.\n",
    "\n",
    "The general syntax looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert <condition>, 'Message if condition is not met'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following example that demonstrates the assert statement paired with a function called times_ten. Note there is a bug in the function for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def times_ten(number):\n",
    "    return number * 100\n",
    " \n",
    "result = times_ten(20)\n",
    "assert result == 200, 'Expected times_ten(20) to return 200, instead got ' + str(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we want to test if our times_ten() function works as intended. We use the assert statement to evaluate the expression result == 200 since we expect that our function would return 200 given an input of 20. Since this is not the case, this expression evaluates to False (there is a bug in times_ten - it actually multiplies by 100!), we get the following exception:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AssertionError: Expected times_ten(20) to return 200, instead got 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An assert statement is a quick and powerful way to verify that a program is in the correct state. They can be used to catch mistakes early and make sure we avoid any catastrophes. Let’s practice using assert to get a feel for automated testing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "#### 1. Small World Air has a program that runs at the check-in kiosk and asks passengers for their destination airport code.\n",
    "\n",
    "Currently, Small World only flies to three destinations: Budapest (BUD), Casablanca (CMN), and Istanbul (IST). Take some time to examine the program.\n",
    "\n",
    "What should the program return for the current set destination of 'HND' (an airport in Tokyo, Japan)?\n",
    "\n",
    "\n",
    "<b>Hint</b><br>\n",
    "What kind of exception gets thrown for a key not existing in a dictionary?\n",
    "\n",
    "#### 2. This error wasn’t a very user-friendly experience! We also want to make sure that users are not entering destinations that Small Air World does not travel to. Let’s add an automated test using assert!\n",
    "\n",
    "Add an assert statement that checks if destination is in the destinations keys. If it isn’t, the AssertionError message should read, 'Sorry, Small World currently does not fly to this destination!'\n",
    "\n",
    "\n",
    "<b>Hint</b><br>\n",
    "The assert keyword is followed by a condition and a message, separated by a comma.\n",
    "\n",
    "The condition should use the in keyword (or the .has_key() function) to check for a specific value in the destinations dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destinations = {\n",
    "  'BUD': 'Budapest',\n",
    "  'CMN': 'Casablanca',\n",
    "  'IST': 'Istanbul'\n",
    "}\n",
    "print('Welcome to Small World Airlines!')\n",
    "print('What is the airport code of your travel destination?')\n",
    "destination = 'HND'\n",
    "\n",
    "\n",
    "# Write your code below: \n",
    "assert destination in destinations, 'Sorry, Small World currently does not fly to this destination!'\n",
    "city_name = destinations[destination]\n",
    "print('Great! Retrieving information for your flight to ...' + city_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Testing\n",
    "Assertion statements are a good start to ensuring our programs are being tested, but they don’t necessarily tell us what we should test. Generally, we can start by testing the smallest unit of a program.\n",
    "\n",
    "For example, in the real world, if we were testing the functionality of a door, we could test a multitude of units. The handle could be an example of a single unit that we must check to make sure a door functions, followed by the hinges and maybe even the lock.\n",
    "\n",
    "In programming, these types of individual tests are called unit tests. Like our door handle, we can test a single unit of a program, such as a function, loop, or variable. A unit test validates a single behavior and will make sure all of the units of a program are functioning properly.\n",
    "\n",
    "Let’s say we wanted to test a single function (a single unit). To test a single function, we might create several test cases. A test case validates that a specific set of inputs produces an expected output for the unit we are trying to test. Let’s examine a test case for our times_ten() function from the previous exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The unit we want to test\n",
    "def times_ten(number):\n",
    "    return number * 100\n",
    " \n",
    "# A unit test function with a single test case\n",
    "def test_multiply_ten_by_zero():\n",
    "    assert times_ten(0) == 0, 'Expected times_ten(0) to return 0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we have a simple test case that validates that times_ten() is behaving as expected for a valid input of 0! We can improve our testing coverage of this function by adding some more test cases with different inputs. A common approach is to create test cases for specific edge case inputs as well as reasonable ones. Here is an example of testing two extreme inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_multiply_ten_by_one_million():\n",
    "    assert times_ten(1000000) == 10000000, 'Expected times_ten(1000000) to return 10000000\n",
    " \n",
    "def test_multiply_ten_by_negative_number():\n",
    "    assert times_ten(-10) == -100, 'Expected times_ten(-10) to return -100'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have several test cases for a wide variety of inputs: a large number, a negative number, and zero. We can create as many test cases as we see fit for a single unit, and we should try to test all the unique types of inputs our unit will work with.\n",
    "\n",
    "Now, let’s create a variety of unit tests for another feature of Small World Air.\n",
    "\n",
    "\n",
    "### Instructions\n",
    "\n",
    "\n",
    "#### 1. At Small Air World, every plane seat has a monitor which displays the nearest emergency exit.\n",
    "\n",
    "This monitor relies on a function called get_nearest_exit(), which takes a row number and then returns an exit location depending on where the row is. Let’s make sure our function is working properly by creating a unit test.\n",
    "\n",
    "Create a function called test_row_1() that will host a test case. Inside the function, assert that a call of get_nearest_exit(1) should equal to 'front', along with a message, 'The nearest exit to row 1 is in the front!'.\n",
    "\n",
    "\n",
    "<b>Hint</b><br>\n",
    "We can call functions within the condition of an assert statement.\n",
    "\n",
    "#### 2. Create another test case function called test_row_20().\n",
    "\n",
    "Inside the function, call get_nearest_exit(20) and assert that the return value is equal to middle, along with the message, 'The nearest exit to row 20 is in the middle!'\n",
    "\n",
    "\n",
    "<b>Hint</b><br>\n",
    "We can call functions within the condition of an assert statement.\n",
    "\n",
    "#### 3. Finally, create another test case function called test_row_40().\n",
    "\n",
    "Inside the function, call get_nearest_exit(40) and assert that the return value is equal to 'back', along with the message, 'The nearest exit to row 40 is in the back!'\n",
    "\n",
    "\n",
    "<b>Hint</b><br>\n",
    "We can call functions within the condition of an assert statement.\n",
    "\n",
    "#### 4. At the bottom of the file, call each of the three test functions we created. What would be the expected output?\n",
    "\n",
    "\n",
    "<b>Hint</b><br>\n",
    "What happens in the get_nearest_exit() function when we test it with the value of 40?\n",
    "\n",
    "#### 5. Looks like our tests caught a logic error in our function get_nearest_exit()! If the row number is larger than 30, we actually want to return 'back'.\n",
    "\n",
    "Adjust the function and fix the error so all of our tests pass (we should see no output).\n",
    "\n",
    "\n",
    "<b>Hint</b><br>\n",
    "What should happen in our else statement in the get_nearest_exit() function for a value of 40?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_exit(row_number):\n",
    "  if row_number < 15:\n",
    "    location = 'front'\n",
    "  elif row_number < 30:\n",
    "    location = 'middle'\n",
    "  else:\n",
    "    # Checkpoint 5\n",
    "    location = 'back'\n",
    "  return location\n",
    "\n",
    "# Checkpoint 1\n",
    "def test_row_1():\n",
    "  assert get_nearest_exit(1) == 'front', 'The nearest exit to row 1 is in the front!'\n",
    "\n",
    "# Checkpoint 2 \n",
    "def test_row_20():\n",
    "  assert get_nearest_exit(20) == 'middle', 'The nearest exit to row 20 is in the middle!'\n",
    "\n",
    "#Checkpoint 3\n",
    "def test_row_40():\n",
    "  assert get_nearest_exit(40) == 'back', 'The nearest exit to row 40 is in the back!'\n",
    "\n",
    "# Checkpoint 4\n",
    "test_row_1()\n",
    "test_row_20()\n",
    "test_row_40()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python's unittest Framework\n",
    "There are some problems with the approach to our previous unit tests that would make them difficult to maintain. First, we had to call each function specifically when a new test was created. We also didn’t have any way of grouping tests, which is necessary when the number of tests increases. Perhaps most importantly, if one test failed, the AssertionError would prevent any remaining tests from running!\n",
    "\n",
    "Luckily, Python provides a framework that solves these problems and provides many other tools for writing unit tests. This framework lives in the unittest module which is included in the standard library. It can be imported like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    " \n",
    "#The rest of our program…."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unittest module provides us with a test runner. A test runner is a component that collects and executes tests and then provides results to the user. The framework also provides many other tools for test grouping, setup, teardown, skipping, and other features that we’ll soon learn about.\n",
    "\n",
    "First, let’s refactor our tests for the times_ten function to use the unittest framework. There are several things we need to do:\n",
    "\n",
    "First, we must create a class which inherits from unittest.TestCase,as follows:."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest \n",
    " \n",
    "class TestTimesTen(unittest.TestCase):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class will serve as the main storage of all our unit testing functions. Once we have the class, we need to change our test functions so that they are methods of the class. The unittest module requires that test functions begin with the word 'test', so our existing names work well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    " \n",
    "class TestTimesTen(unittest.TestCase):\n",
    "    def test_multiply_ten_by_zero(self):\n",
    "        pass\n",
    " \n",
    "    def test_multiply_ten_by_one_million(self):\n",
    "        pass\n",
    " \n",
    "    def test_multiply_ten_by_negative_number(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we need to change our assert statements to use the assertEqual method of unittest.TestCase. The framework requires that we use special methods instead of standard assert statements. Don’t worry we’ll cover these methods in the remainder of this lesson, for now, simply get used to the syntax. Here is what our class looks after the change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    " \n",
    "class TestTimesTen(unittest.TestCase):\n",
    "    def test_multiply_ten_by_zero(self):\n",
    "        self.assertEqual(times_ten(0), 0, 'Expected times_ten(0) to return 0')\n",
    " \n",
    "    def test_multiply_ten_by_one_million(self):\n",
    "        self.assertEqual(times_ten(1000000), 10000000, 'Expected times_ten(1000000) to return 10000000')\n",
    " \n",
    "    def test_multiply_ten_by_negative_number(self):\n",
    "        self.assertEqual(times_ten(-10), -100, 'Expected add_times_ten(-10) to return -100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That’s it! Now we can run our tests by calling unittest.main(). The unittest framework will work its magic to detect any tests in the existing module, run them, and provide us results. Our final code would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing unittest framework\n",
    "import unittest\n",
    " \n",
    "# Function that gets tested\n",
    "def times_ten(number):\n",
    "    return number * 100\n",
    " \n",
    "# Test class\n",
    "class TestTimesTen(unittest.TestCase):\n",
    "    def test_multiply_ten_by_zero(self):\n",
    "        self.assertEqual(times_ten(0), 0, 'Expected times_ten(0) to return 0')\n",
    " \n",
    "    def test_multiply_ten_by_one_million(self):\n",
    "        self.assertEqual(times_ten(1000000), 10000000, 'Expected times_ten(1000000) to return 10000000')\n",
    " \n",
    "    def test_multiply_ten_by_negative_number(self):\n",
    "        self.assertEqual(times_ten(-10), -100, 'Expected add_times_ten(-10) to return -100')\n",
    " \n",
    "# Run the tests\n",
    "unittest.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run this code, we would see the following output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FF.\n",
    "======================================================================\n",
    "FAIL: test_multiply_ten_by_negative_number (__main__.TestTimesTen)\n",
    "----------------------------------------------------------------------\n",
    "Traceback (most recent call last):\n",
    "  File \"scratch.py\", line 16, in test_multiply_ten_by_negative_number\n",
    "    self.assertEqual(times_ten(-10), -100, 'Expected add_times_ten(-10) to return -100')\n",
    "AssertionError: -1000 != -100 : Expected add_times_ten(-10) to return -100\n",
    "\n",
    "======================================================================\n",
    "FAIL: test_multiply_ten_by_one_million (__main__.TestTimesTen)\n",
    "----------------------------------------------------------------------\n",
    "Traceback (most recent call last):\n",
    "  File \"scratch.py\", line 13, in test_multiply_ten_by_one_million\n",
    "    self.assertEqual(times_ten(1000000), 10000000, 'Expected times_ten(1000000) to return 10000000')\n",
    "AssertionError: 100000000 != 10000000 : Expected times_ten(1000000) to return 10000000\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "Ran 3 tests in 0.001s\n",
    "\n",
    "FAILED (failures=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the test output, we can see that two of the tests failed (test_multiply_ten_by_one_million and test_multiply_ten_by_negative_number).\n",
    "\n",
    "Let’s get some practice with unittest by refactoring our previous test cases for Small World Air and then we will dive into learning all the useful testing methods we can work with!\n",
    "\n",
    "### Instructions\n",
    "#### 1. First, let’s import unittest at the top of the file.\n",
    "\n",
    "\n",
    "<b>Hint</b><br>\n",
    "To import a built-in Python module we can use the following syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import <module name>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Next, after the get_nearest_exit() function, create a class called NearestExitTests. It should inherit from unittest.TestCase.\n",
    "\n",
    "\n",
    "<b>Hint</b><br>\n",
    "To setup a test class, we use the following syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testClass(unittest.TestCase): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Refactor test_row_1(), test_row_20(), and test_row_40() so that they are methods of this class. Don’t forget to add the self argument.\n",
    "\n",
    "\n",
    "<b>Hint</b><br>\n",
    "Indent the functions to make them part of the class body and thus methods.\n",
    "\n",
    "\n",
    "4. Change the assert statements in these functions so that they instead call the self.assertEqual() method with the correct arguments.\n",
    "\n",
    "\n",
    "<b>Hint</b><br>\n",
    "self.assertEqual() should have three arguments: the value returned by get_nearest_exit(), the expected return value, and the message. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.assertEqual(<function call>, <value to compare function call to>, <error message>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Remove the three function calls from the bottom of the file. Replace them with a single call to unittest.main(). Observe the output of our tests!\n",
    "\n",
    "\n",
    "#### 6. Looks like it’s the same bug from before! Fix the error in the get_nearest_exit() function. We should no longer get any failed tests when we run our script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code below:\n",
    "import unittest\n",
    "\n",
    "def get_nearest_exit(row_number):\n",
    "  if row_number < 15:\n",
    "    location = 'front'\n",
    "  elif row_number < 30:\n",
    "    location = 'middle'\n",
    "  else:\n",
    "    location = 'back'\n",
    "  return location\n",
    "\n",
    "# Write your code below:\n",
    "class NearestExitTests(unittest.TestCase):\n",
    "\n",
    "  def test_row_1(self):\n",
    "    self.assertEqual(get_nearest_exit(1), 'front', 'The nearest exit to row 1 is in the front!')\n",
    "\n",
    "  def test_row_20(self):\n",
    "    self.assertEqual(get_nearest_exit(20), 'middle', 'The nearest exit to row 20 is in the middle!')\n",
    "\n",
    "  def test_row_40(self):\n",
    "    self.assertEqual(get_nearest_exit(40), 'back', 'The nearest exit to row 40 is in the back!')\n",
    "\n",
    "unittest.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assert Methods I: Equality and Membership\n",
    "In the last exercise, we saw how to check for equality between two values in the unittest framework using the .assertEqual method of the TestCase class. The framework relies on built-in assert methods instead of assert statements to track results without actually raising any exceptions. Specific assert methods take arguments instead of a condition, and like assert statements, they can take an optional message argument.\n",
    "\n",
    "Let’s go over three commonly used assert methods for testing equality and membership, their general syntax, and their assert statement equivalents.\n",
    "\n",
    "- assertEqual: The assertEqual() method takes two values as arguments and checks that they are equal. If they are not, the test fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " self.assertEqual(value1, value2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- assertIn: The assertIn() method takes two arguments. It checks that the first argument is found in the second argument, which should be a container. If it is not found in the container, the test fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " self.assertIn(value, container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- assertTrue: The assertTrue() method takes a single argument and checks that the argument evaluates to True. If it does not evaluate to True, the test fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " self.assertTrue(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equivalent assert statements would be the following:\n",
    "\n",
    "Method\tEquivalent\n",
    "self.assertEqual(2, 5)\tassert 2 == 5\n",
    "self.assertIn(5, [1, 2, 3])\tassert 5 in [1, 2, 3]\n",
    "self.assertTrue(0)\tassert bool(0) is True\n",
    "\n",
    "\n",
    "The full list for equality and membership can be seen in the Python documentation. Let’s put these methods into practice!\n",
    "\n",
    "\n",
    "Instructions\n",
    "\n",
    "\n",
    "#### 1. Small World Air planes are equipped with an on-board entertainment system which we need to create some tests for. Take some time to review entertainment.py and tests.py.\n",
    "\n",
    "Note the three functions in entertainment.py:\n",
    "\n",
    "1. get_daily_movie(): returns the movie of the day.\n",
    "\n",
    "2. get_licensed_movies(): returns a list of licensed movies the plane can play.\n",
    "\n",
    "3. get_wifi_status(): returns the current wifi status of the plane.\n",
    "\n",
    "4. Note the two test cases in tests.py:\n",
    "\n",
    "5. test_movie_license(): is intended to test if a daily movie is licensed\n",
    "\n",
    "6. test_wifi_status(): is intended to test if the wifi is currently active\n",
    "\n",
    "\n",
    "Run the code to proceed.\n",
    "\\\n",
    "#### 2. Every flight has a free movie. We want to create a test that checks our database to make sure that the uploaded movie has a valid license, or else we could pay some hefty fines.\n",
    "\n",
    "Inside of our test_movie_license() test method, we have two variables defined:\n",
    "\n",
    "- daily_movie: which stores the value of the current free daily movie.\n",
    "- licensed_movies: which stores the value of all the current licensed movies.\n",
    "\n",
    "\n",
    "To test if we have a license for the current daily movie, we need to compare if daily_movie exists inside of licensed_movies.\n",
    "\n",
    "\n",
    "Use the self.assertIn() assert method inside of test_movie_license() to check if the daily_movie is licensed.\n",
    "\n",
    "\n",
    "<B>Hint</b><br>\n",
    "self.assertIn() has two required arguments: an element, followed by a container that we expect to contain that element.\n",
    "\n",
    "#### 3. Our entertainment system also provides WiFi as a purchase option for passengers. We want to make a test that ensures the WiFi is enabled.\n",
    "\n",
    "Inside the test method called test_wifi_status() we have a variable called wifi_enabled which stores the boolean value of whether the wifi is turned on or not.\n",
    "\n",
    "Use the self.assertTrue() assert method inside of test_wifi_status() to test that wifi_enabled is True. The test should fail because currently wifi is disabled.\n",
    "\n",
    "\n",
    "<b>Hint</b><br>\n",
    "self.assertTrue() has one required argument - an element we want to check the boolean value of!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import entertainment\n",
    "\n",
    "# Write your code below: \n",
    "class EntertainmentSystemTests(unittest.TestCase):\n",
    "\n",
    "  def test_movie_license(self):\n",
    "    daily_movie = entertainment.get_daily_movie()\n",
    "    licensed_movies = entertainment.get_licensed_movies()\n",
    "    self.assertIn(daily_movie, licensed_movies)\n",
    "\n",
    "  def test_wifi_status(self):\n",
    "    wifi_enabled = entertainment.get_wifi_status()\n",
    "    self.assertTrue(wifi_enabled)\n",
    "\n",
    "unittest.main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assert Methods II: Quantitative Methods\n",
    "Often we need to test conditions related to numbers. The unittest module provides a handful of assert methods to achieve this. Let’s take a look at two common assert methods related to quantitative comparisons, their general syntax, as well as their assert statement equivalents.\n",
    "\n",
    "- assertLess: The assertLess() method takes two arguments and checks that the first argument is less than the second one. If it is not, the test will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " self.assertLess(value1, value2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- assertAlmostEqual: The assertAlmostEqual() method takes two arguments and checks that their difference, when rounded to 7 decimal places, is 0. In other words, if they are almost equal. If the value is close enough to equality, the test will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " self.assertAlmostEqual(value1, value2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equivalent assert statements would be the following:\n",
    "\n",
    "Method\tEquivalent\n",
    "self.assertLess(2, 5)\tassert 2 < 5\n",
    "self.assertAlmostEqual(.22, .225)\tassert round(.22 - .225, 7) == 0\n",
    "\n",
    "The full list of quantitative methods can be seen in the Python documentation. Let’s put these methods into practice!\n",
    "\n",
    "\n",
    "### Instructions\n",
    "\n",
    "\n",
    "Our entertainment.py file has a function called get_maximum_display_brightness() that returns the max screen brightness value.\n",
    "\n",
    "Create a test method called test_maximum_display_brightness(). Inside the method, do the following:\n",
    "\n",
    "1. Call entertainment.get_maximum_display_brightness() and store the return value in a variable called brightness.\n",
    "\n",
    "2. Next, call self.assertAlmostEqual() to make sure that brightness is almost equal to 400.\n",
    "\n",
    "\n",
    "<b>Hint</b><br>\n",
    "self.assertAlmostEqual() requires two numbers as arguments.\n",
    "\n",
    "#### 2. Our entertainment.py file has a method called entertainment.get_device_temp() that returns the current device temperature.\n",
    "\n",
    "Create a test method called test_device_temperature(). Inside the method do the following:\n",
    "\n",
    "1. Call entertainment.get_device_temp() and store the return value in a variable called device_temp.\n",
    "\n",
    "2. Then call self.assertLess() to make sure that device_temp is less than 35.\n",
    "\n",
    "The test should fail because the current temperature is 40.\n",
    "\n",
    "\n",
    "<b>Hint</b><br>\n",
    "self.assertLess() requires two numbers as arguments. The first one is expected to be less than the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import entertainment\n",
    "\n",
    "class EntertainmentSystemTests(unittest.TestCase):\n",
    "\n",
    "  def test_movie_license(self):\n",
    "    daily_movie = entertainment.get_daily_movie()\n",
    "    licensed_movies = entertainment.get_licensed_movies()\n",
    "    self.assertIn(daily_movie, licensed_movies)\n",
    "\n",
    "  def test_wifi_status(self):\n",
    "    wifi_enabled = entertainment.get_wifi_status()\n",
    "    self.assertTrue(wifi_enabled)\n",
    "\n",
    "  # Write your code below:\n",
    "  def test_maximum_display_brightness(self):\n",
    "    brightness = entertainment.get_maximum_display_brightness()\n",
    "    self.assertAlmostEqual(brightness, 400)\n",
    "\n",
    "  def test_device_temperature(self):\n",
    "    device_temp = entertainment.get_device_temp()\n",
    "    self.assertLess(device_temp, 35)\n",
    "unittest.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assert Methods III: Exception and Warning Methods\n",
    "There is another group of assert methods related to exceptions and warnings. Note that while we haven’t covered warnings in detail yet, they are a type of exception. Let’s go over two of these methods and their general syntax.\n",
    "\n",
    "- assertRaises: The assertRaises() method takes an exception type as its first argument, a function reference as its second, and an arbitrary number of arguments as the rest.\n",
    "\n",
    "It calls the function and checks if an exception is raised as a result. The test passes if an exception is raised, is an error if another exception is raised, or fails if no exception is raised. This method can be used with custom exceptions as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.assertRaises(specificException, function, functionArguments...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assertWarns: The assertWarns() method takes a warning type as its first argument, a function reference as its second, and an arbitrary number of arguments for the rest.\n",
    "\n",
    "It calls the function and checks that the warning occurs. The test passes if a warning is triggered and fails if it isn’t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.assertWarns(specificWarningException, function, functionArguments...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no particular concise ways to replicate these tests using the assert keyword so it is recommended to use these methods instead when possible!\n",
    "\n",
    "The full list of exception and warning methods can be seen in the Python documentation. Let’s put these methods into practice!\n",
    "\n",
    "### Instructions\n",
    "#### 1. We need to create some tests for the airplane alert system so that the flight crew is properly notified of critical events.\n",
    "\n",
    "Let’s start by creating a class called SystemAlertTests which inherits from unittest.TestCase.\n",
    "\n",
    "\n",
    "<b>Hint</b><br>\n",
    "A class can inherit from another using the following syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomClass(classToInherit):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. We are going to create a test for any power outages that might occur on the airplane. Check out the custom exception PowerError and our function that raises the error power_outage_detected() in the alerts.py file. The file is already imported into tests.py for us.\n",
    "\n",
    "In our SystemAlertTests class, create a test method called test_power_outage_alert().\n",
    "\n",
    "Inside the new method, use self.assertRaises() to check that an alerts.PowerError is raised whenever alerts.power_outage_detected is called with an argument of True.\n",
    "\n",
    "This test should pass since we are passing a value of True and the exception is raised.\n",
    "\n",
    "\n",
    "<b>Hint</b><br>\n",
    "The general syntax for assertRaises() is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.assertRaises(specificException, function, functionArguments...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our scenario here is each component:\n",
    "\n",
    "- SpecificException: This would be our PowerError custom exception from alerts.py. Remember, to use an imported function, we must preface it with alerts. since that is the file it originated from.\n",
    "\n",
    "- Function: This would be our power_outage_detected() function. For this syntax, we omit the parenthesis() since we are not calling the function. Remember, to use an imported function, we must preface it with alerts. since that is the file it originated from.\n",
    "\n",
    "- Function Arguments: We want to pass the function above the argument of True\n",
    "\n",
    "Alternatively, we can the function arguments directly into the function, in which case we do not omit the parenthesis () and pass the True argument directly into the parenthesis, with no additional arguments.\n",
    "\n",
    "#### 3. We are going to create a test for any water level warnings that occur on the airplane. Check out the custom exception WaterLevelWarning and our function that raises the warning water_levels_check() in the alerts.py file. The file is already imported into tests.py for us.\n",
    "\n",
    "In our SystemAlertTests class, create a test method called test_water_levels_warning().\n",
    "\n",
    "Inside the new method, use self.assertWarns() to check that an alerts.WaterLevelWarning is raised whenever alerts.water_levels_check is called with an argument of 150 liters.\n",
    "\n",
    "This test should pass since we are passing a value less than 200 and a warning occurs.\n",
    "\n",
    "\n",
    "<b>Hint</b><br>\n",
    "The general syntax for assertWarns() is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.assertWarns(specificWarning, function, functionArguments...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our scenario here is each component:\n",
    "\n",
    "- SpecificWarning: This would be our WaterLevelWarning custom warning from alerts.py. Remember, to use an imported function, we must preface it with alerts. since that is the file it originated from.\n",
    "\n",
    "- Function: This would be our water_levels_check() function. For this syntax, we omit the parenthesis() since we are not calling the function. Remember, to use an imported function, we must preface it with alerts. since that is the file it originated from.\n",
    "\n",
    "- Function Arguments: We want to pass the function above the argument of 150\n",
    "\n",
    "Alternatively, we can the function arguments directly into the function, in which case we do not omit the parenthesis () and pass the True argument directly into the parenthesis, with no additional arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import alerts\n",
    "\n",
    "# Write your code here:\n",
    "class SystemAlertTests(unittest.TestCase):\n",
    "  \n",
    "  def test_power_outage_detected(self):\n",
    "    self.assertRaises(alerts.PowerError, alerts.power_outage_detected, True)\n",
    "\n",
    "  def test_water_levels_warning(self):\n",
    "    self.assertWarns(alerts.WaterLevelWarning, alerts.water_levels_check, 150)\n",
    "unittest.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameterizing Tests\n",
    "In previous examples, we created test cases for the add_ten() function with various inputs. However, the actual logic of our tests really didn’t change. To decrease repetition, Python provides us a specific toolset for tests with only minor differences. This is known as test parameterization. By parameterizing tests, we can leverage the functionality of a single test to get a large amount of coverage of different inputs.\n",
    "\n",
    "To accomplish test parameterization, the unittest framework provides us with the subTest context manager. Let’s refactor our previous test class to utilize it and see it in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    " \n",
    "# The function we want to test\n",
    "def times_ten(number):\n",
    "    return number * 100\n",
    " \n",
    "# Our test class\n",
    "class TestTimesTen(unittest.TestCase):\n",
    " \n",
    "    # A test method\n",
    "    def test_times_ten(self):\n",
    "        for num in [0, 1000000, -10]:\n",
    "            with self.subTest():\n",
    "                expected_result = num * 10\n",
    "                message = 'Expected times_ten(' + str(num) + ') to return ' + str(expected_result)\n",
    "                self.assertEqual(times_ten(num), expected_result, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, in our test method test_times_ten(), instead of writing individual test cases for each input of 0, 10, and 1000000, we can test a collection of inputs by using a loop followed by a with statement and our subTest context manager.\n",
    "\n",
    "By using subTest, each iteration of our loop is treated as an individual test. Python will run the code inside of the context manager on each iteration, and if one fails, it will return the failure as a separate test case failure.\n",
    "\n",
    "Just like before, we are using the assertEqual() method to check the expected result, and we are expecting (due to an error in times_ten()) that the cases of using an input of -10 and 1000000 will fail.\n",
    "\n",
    "Here is the new output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "======================================================================\n",
    "FAIL: test_times_ten (__main__.TestTimesTen) (<subtest>)\n",
    "----------------------------------------------------------------------\n",
    "Traceback (most recent call last):\n",
    "  File \"scratch.py\", line 12, in test_times_ten\n",
    "    self.assertEqual(times_ten(num), expected_result, message)\n",
    "AssertionError: 100000000 != 10000000 : Expected times_ten(1000000) to return 10000000\n",
    "\n",
    "======================================================================\n",
    "FAIL: test_times_ten (__main__.TestTimesTen) (<subtest>)\n",
    "----------------------------------------------------------------------\n",
    "Traceback (most recent call last):\n",
    "  File \"scratch.py\", line 12, in test_times_ten\n",
    "    self.assertEqual(times_ten(num), expected_result, message)\n",
    "AssertionError: -1000 != -100 : Expected times_ten(-10) to return -100\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "Ran 1 test in 0.000s\n",
    "\n",
    "FAILED (failures=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to expand our test coverage, we can simply modify the list that our loop iterates over. We can test a range of thousands of inputs simply by using the context manager setup to achieve test parameterization.\n",
    "\n",
    "Optionally, we can give our subtests better readability by making a small change in our code for the first argument of self.subTest(). The below code has most of our script omitted for brevity but uses the same script we executed above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... more code above..\n",
    " \n",
    "for num in [0, 1000000, -10]:\n",
    "  with self.subTest(num):\n",
    " \n",
    "# ... more code below ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes our test clearer, because our test error message goes from:\n",
    "\n",
    "\n",
    "FAIL: test_times_ten (__main__.TestTimesTen) (<subtest>)\n",
    "\n",
    "\n",
    "to:\n",
    "\n",
    "FAIL: test_times_ten (__main__.TestTimesTen) [1000000]\n",
    "\n",
    "\n",
    "When working with large amounts of test inputs, it is much easier to distinguish which case failed. We can actually use any message we want as the first argument, but using the tested case is usually the best way to increase readability for ourselves and other developers.\n",
    "\n",
    "By using test parameterization, we made our codebase much cleaner and more maintainable. Let’s get some practice by refactoring some of our previous tests!\n",
    "\n",
    "### Instructions\n",
    "#### 1. Small World Air is growing and has added many more movie options to the entertainment system (we can see them inside of entertainment.py).\n",
    "\n",
    "Let’s adjust our EntertainSystemTests class to make sure they all get tested. Replace the call to entertainment.get_daily_movie() with entertainment.get_daily_movies() (our new method).\n",
    "\n",
    "Lastly, for better readability, update the variable name daily_movie to daily_movies. After updating this variable name, update the first argument in the call to self.assertIn() to use this new variable name.\n",
    "\n",
    "\n",
    "#### 2. Under our two variables, write a for loop that iterates over daily_movies and stores each iteration value into a variable called movie. For now, let’s simply print movie on each iteration.\n",
    "\n",
    "\n",
    "<b>Hint</b><br>\n",
    "The basic structure of a for loop looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in collection:\n",
    "  #some code to execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, our element is named movie and our collection is daily_movies.\n",
    "\n",
    "\n",
    "#### 3. Indent our self.assertIn() call to be inside the for loop and change the first argument in self.assertIn() from daily_movie to movie to represent the individual movies on each iteration of the loop.\n",
    "\n",
    "Note: Creating this structure might be okay at first glance (and may even make you wonder why we need the context manager), but if we run our test, we will see that the test will fail in the middle of our movies collection and won’t check the rest (it stops at Black Widow and not Spiral)! This is because like many testing frameworks, unittest will fail and stop on the first failure it encounters.\n",
    "\n",
    "\n",
    "#### 4. Lastly, under our print statement of movie but before our assertIn() call, insert a self.subTest() to wrap our test method. To make sure we can distinguish test cases between each movie, pass a single argument of movie into self.subTest().\n",
    "\n",
    "Don’t forget to preface the context manager with a with statement and indent our self.assertIn() statement. Now, we can observe testing multiple movies and if they are licensed or not.\n",
    "\n",
    "\n",
    "<b>Hint</b><br>\n",
    "Our general structure should look like this (with spacing representing indentation levels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loop\n",
    "    print statement\n",
    "    with statement using subTest()\n",
    "        assertIn() test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import entertainment\n",
    "\n",
    "class EntertainmentSystemTests(unittest.TestCase):\n",
    "\n",
    "  def test_movie_license(self):\n",
    "    # Checkpoint 1\n",
    "    daily_movies = entertainment.get_daily_movies()\n",
    "    licensed_movies = entertainment.get_licensed_movies()\n",
    "\n",
    "    # Checkpoint 2\n",
    "    for movie in daily_movies:\n",
    "      print(movie)\n",
    "      # Checkpoint 3 & 4\n",
    "      with self.subTest(movie):\n",
    "        self.assertIn(movie, licensed_movies)\n",
    "\n",
    "\n",
    "unittest.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Fixtures\n",
    "One of the most important principles of testing is that tests need to occur in a known state. If the conditions in which a test runs are not controlled, then our results could contain false negatives (invalid failed results) or false positives (invalid passed results).\n",
    "\n",
    "This is where test fixtures come in. A test fixture is a mechanism for ensuring proper test setup (putting tests into a known state) and test teardown (restoring the state prior to the test running). Test fixtures guarantee that our tests are running in predictable conditions, and thus the results are reliable.\n",
    "\n",
    "Let’s say we are testing a Bluetooth device. The device’s Bluetooth module can sometimes fail. When this happens, the device needs to be power cycled (shut off and then on) to restore Bluetooth functionality. We would not want tests to run if the device was already in a failed state because these results would not be valid. Furthermore, if our tests cause the Bluetooth module to fail, we want to restore it to a working state after the tests run. So, we add a test fixture to power cycle the device before and after each test. Here is how we might do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_cycle_device():\n",
    "    print('Power cycling bluetooth device...')\n",
    " \n",
    "class BluetoothDeviceTests(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        power_cycle_device()\n",
    " \n",
    "    def test_feature_a(self):\n",
    "        print('Testing Feature A')\n",
    " \n",
    "    def test_feature_b(self):\n",
    "        print('Testing Feature B')\n",
    " \n",
    "    def tearDown(self):\n",
    "        power_cycle_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unittest framework automatically identifies setup and teardown methods based on their names. A method named setUp runs before each test case in the class. Similarly, a method named tearDown gets called after each test case. Now, we can guarantee that our Bluetooth module is in a working state before and after every test. Here is the output when these tests are run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Power cycling bluetooth device...\n",
    "Testing Feature A\n",
    "Power cycling bluetooth device...\n",
    ".Power cycling bluetooth device...\n",
    "Testing Feature B\n",
    "Power cycling bluetooth device...\n",
    ".\n",
    "----------------------------------------------------------------------\n",
    "Ran 2 tests in 0.000s\n",
    " \n",
    "OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s consider another scenario. Perhaps our tests rely on working Bluetooth, but there is nothing in the tests that would cause the bluetooth to stop working. In this case, it would be inefficient to power cycle the device before and after every test. Let’s refactor the previous example so that setup and teardown only happen once - before and after all tests in the class are run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_cycle_device():\n",
    "    print('Power cycling bluetooth device...')\n",
    " \n",
    "class BluetoothDeviceTests(unittest.TestCase):\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        power_cycle_device()\n",
    " \n",
    "    def test_feature_a(self):\n",
    "        print('Testing Feature A')\n",
    " \n",
    "    def test_feature_b(self):\n",
    "        print('Testing Feature B')\n",
    " \n",
    "    @classmethod\n",
    "    def tearDownClass(cls):\n",
    "        power_cycle_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We replaced our setUp method with the setUpClass method and added the @classmethod decorator. We changed the argument from self to cls because this is a class method. Similarly, we replaced the tearDown method with the tearDownClass class method. Now, we get the following output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Power cycling bluetooth device...\n",
    "Testing Feature A\n",
    "Testing Feature B\n",
    "Power cycling bluetooth device...\n",
    " \n",
    "----------------------------------------------------------------------\n",
    "Ran 2 tests in 0.000s\n",
    " \n",
    "OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to calling functions, we can also use setup methods to instantiate objects and or gather any other data needed. Anything stored in our class will be available throughout our test functions.\n",
    "\n",
    "It’s generally good practice to create fixtures that run for every test. However, when a fixture has a large cost (i.e. it takes a long time), then it might make more sense to have it run once per test class rather than once per test. Let’s practice setting up test fixtures!\n",
    "\n",
    "### Instructions\n",
    "#### 1. In our tests.py file we have some simple tests written for the passenger check-in experience at the kiosk for Small World Air. We also have some functions we are testing written in kiosk.py.\n",
    "\n",
    "Take some time to review the provided code in both files. Run the code to continue!\n",
    "\n",
    "#### 2. We want to make sure the kiosk is powered on before we run any tests. This is a great time to setup some test fixtures!\n",
    "\n",
    "Create a setUpClass() method which takes a single argument (cls) and calls kiosk.power_on_kiosk(). Add the @classmethod decorator on top of it!\n",
    "\n",
    "\n",
    "<b>Hint</b><br>\n",
    "Python detects setup test fixtures that run once by looking for methods with the name setUpClass.\n",
    "\n",
    "#### 3. We don’t want to leave the kiosk powered on after all tests are run.\n",
    "\n",
    "Create a tearDownClass() method which takes a single argument (cls) and calls kiosk.power_off_kiosk()’. Add the@classmethod` decorator on top of it!\n",
    "\n",
    "\n",
    "<b>Hint</b><br>\n",
    "Python detects teardown test fixtures that run once by looking for methods with the name tearDownClass.\n",
    "\n",
    "#### 4. We also want to make sure that customers are on the welcome page before each test runs. Create a method called setUp(). Inside of the method, call kiosk.return_to_welcome_page().\n",
    "\n",
    "\n",
    "<b>Hint</b><br>\n",
    "Python detects setup test fixtures that run on every test by looking for methods with the name setUp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 1\n",
    "import unittest\n",
    "import kiosk\n",
    "\n",
    "\n",
    "class CheckInKioskTests(unittest.TestCase):\n",
    "\n",
    "  def test_check_in_with_flight_number(self):\n",
    "    print('Testing the check-in process based on flight number')\n",
    "\n",
    "  def test_check_in_with_passport(self):\n",
    "    print('Testing the check-in process based on passport')\n",
    "\n",
    "  # Checkpoint 2\n",
    "  @classmethod\n",
    "  def setUpClass(cls):\n",
    "    kiosk.power_on_kiosk()\n",
    "    \n",
    "  # Checkpoint 3\n",
    "  @classmethod\n",
    "  def tearDownClass(cls):\n",
    "    kiosk.power_off_kiosk()\n",
    "    \n",
    "  # Checkpoint 4\n",
    "  def setUp(self):\n",
    "    kiosk.return_to_welcome_page()\n",
    "\n",
    "unittest.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skipping tests\n",
    "Sometimes we have tests that should only run in a particular context. For example, we might have a group of tests that only runs on the Windows operating system but not Linux or macOS. For these situations, it’s helpful to be able to skip tests.\n",
    "\n",
    "The unittest framework provides two different ways to skip tests:\n",
    "\n",
    "1. The @unittest skip decorator\n",
    "2. The skipTest() method\n",
    "First, let’s examine the skip decorator option. There are two decorator options to accomplish the goal of skipping a test. Let’s observe both of them in the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    " \n",
    "class LinuxTests(unittest.TestCase):\n",
    " \n",
    "    @unittest.skipUnless(sys.platform.startswith(\"linux\"), \"This test only runs on Linux\")\n",
    "    def test_linux_feature(self):\n",
    "        print(\"This test should only run on Linux\")\n",
    " \n",
    "    @unittest.skipIf(not sys.platform.startswith(\"linux\"), \"This test only runs on Linux\")\n",
    "    def test_other_linux_feature(self):\n",
    "        print(\"This test should only run on Linux\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s break down both skip decorator options:\n",
    "\n",
    "- The skipUnless option skips the test if the condition evaluates to False.\n",
    "\n",
    "- The skipIf option skips the test if the condition evaluates to True.\n",
    "\n",
    "Both share common requirements. Firstly, both of these skip decorators are prefaced with @unittest to denote the decorator pattern. They both take a condition as a first argument, followed by a string message as the second. In this example, both decorators achieve the same goal: skipping the test if the operating system is not Linux.\n",
    "\n",
    "If we ran the tests on a macOS system, we would get the following output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss\n",
    "----------------------------------------------------------------------\n",
    "Ran 2 tests in 0.000s\n",
    " \n",
    "OK (skipped=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second way to skip tests is to call the skipTest method of the TestCase class, as in this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    " \n",
    "class LinuxTests(unittest.TestCase):\n",
    " \n",
    "    def test_linux_feature(self):\n",
    "        if not sys.platform.startswith(\"linux\"):\n",
    "            self.skipTest(\"Test only runs on Linux\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we call self.skipTest() from within the test function itself. It takes a single string message as its argument and always causes the test to be skipped when called. When run on macOS we get the following output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s\n",
    "----------------------------------------------------------------------\n",
    "Ran 1 test in 0.000s\n",
    " \n",
    "OK (skipped=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip decorators are slightly more convenient and make it easy to see under what conditions the test is skipped. When the conditions for skipping a test are too complicated to pass into a skip decorator, the skipTest method is the recommended alternative.\n",
    "\n",
    "Let’s practice skipping tests in our Small World Air application!\n",
    "\n",
    "### Instructions\n",
    "#### 1. Small World Air continues to grow! They recently added some regional jets for shorter flights. Unfortunately, these planes don’t have an onboard entertainment system.\n",
    "\n",
    "Let’s modify our EntertainmentSystemTests to make sure these tests get skipped on regional jets. Use the @unittest.skipIf() decorator to test_movie_license().\n",
    "\n",
    "It should skip the test if entertainment.regional_jet() returns True. The message should output 'Not available on regional jets'.\n",
    "\n",
    "\n",
    "<b>Hint</b><br>\n",
    "The unittest.skipIf() takes two arguments. The first is a condition (it can be the result of a functional call). If the condition is True, the test is skipped. The second argument is a string which is the skip message.\n",
    "\n",
    "#### 2. Add the @unittest.skipUnless decorator to test_wifi_status().\n",
    "\n",
    "It should skip the test unless entertainment.regional_jet() returns False. The message should be 'Not available on regional jets'.\n",
    "\n",
    "\n",
    "<b>Hint</b><br>\n",
    "unittest.skipUnless() takes two arguments. The first is a condition (it can be the result of a function call). If the condition is False, the test is skipped. The second argument is a string which is the skip message.\n",
    "\n",
    "#### 3. Inside of test_device_temperature(), add an if statement which calls entertainment.regional_jet(). If the return value is True, then call self.skipTest() with an argument of 'Not available on regional jets'.\n",
    "\n",
    "Add the same if block to test_maximum_display_brightness().\n",
    "\n",
    "\n",
    "<b>Hint</b><br>\n",
    "skipTest() does not take a condition argument - it always skips the test when called. It takes a message as its only argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import entertainment\n",
    "\n",
    "class EntertainmentSystemTests(unittest.TestCase):\n",
    "\n",
    "  @unittest.skipIf(entertainment.regional_jet(), 'Not available on regional jets')\n",
    "  def test_movie_license(self):\n",
    "    daily_movie = entertainment.get_daily_movie()\n",
    "    licensed_movies = entertainment.get_licensed_movies()\n",
    "    self.assertIn(daily_movie, licensed_movies)\n",
    "\n",
    "  @unittest.skipUnless(entertainment.regional_jet() is False, 'Not available on regional jets')\n",
    "  def test_wifi_status(self):\n",
    "    wifi_enabled = entertainment.get_wifi_status()\n",
    "    self.assertTrue(wifi_enabled)\n",
    "\n",
    "  def test_device_temperature(self):\n",
    "    if entertainment.regional_jet():\n",
    "      self.skipTest('Not available on regional jets')\n",
    "    device_temp = entertainment.get_device_temp()\n",
    "    self.assertLess(device_temp, 35)\n",
    "\n",
    "  def test_maximum_display_brightness(self):\n",
    "    if entertainment.regional_jet():\n",
    "      self.skipTest('Not available on regional jets')\n",
    "    brightness = entertainment.get_maximum_display_brightness()\n",
    "    self.assertAlmostEqual(brightness, 400)\n",
    "\n",
    "\n",
    "unittest.main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Failures\n",
    "Sometimes we have a test that we know will fail. This could happen when a feature has a known bug or is designed to fail on purpose. In this case, we wouldn’t want an expected failure to cloud our test results. Rather than simply skipping the test, unittest provides a way to mark tests as expected failures. Expected failures are counted as passed in our test results. If the test passes when we expected it to fail, then it is marked as failed in test results.\n",
    "\n",
    "To setup a test to have an expected failure, we can use the expectedFailure decorator. Let’s consider the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureTests(unittest.TestCase):\n",
    " \n",
    "    @unittest.expectedFailure\n",
    "    def test_broken_feature(self):\n",
    "        raise Exception(\"This test is going to fail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expectedFailure decorator takes no arguments. The test in the example will always fail because an exception was raised during test execution. When run, we get the following output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x\n",
    "----------------------------------------------------------------------\n",
    "Ran 1 test in 0.000s\n",
    " \n",
    "OK (expected failures=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test failure did not cause any failures in our test results because it was marked as expected. Let’s do the same for some of our Small World Air tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "#### 1. The monitors in front of passenger seats on Small World planes contain a customer feedback portal. The class CustomerFeedbackTests has tests for both the survey and the complaint form.\n",
    "\n",
    "We can find the tests in tests.py and the functions that perform feedback tasks in feedback.py. Take some time to get acquainted with the program. Run the code to move on!\n",
    "\n",
    "#### 2. Looks like test_survey_form() caught a bug in the customer survey form! It’s best not to have this test fail every day while we wait for the bug to get fixed.\n",
    "\n",
    "Use the expectedFailure decorator to mark this test as an expected failure!\n",
    "\n",
    "\n",
    "<b>Hint</b><br>\n",
    "The @unittest.expectedFailure decorator marks a test function as an expected failure. It expects no arguments and is not executed using parenthesis ()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import feedback\n",
    "\n",
    "class CustomerFeedbackTests(unittest.TestCase):\n",
    "\n",
    "  # Write your code below:\n",
    "  @unittest.expectedFailure\n",
    "  def test_survey_form(self):\n",
    "    self.assertEqual(feedback.issue_survey(), 'Success')\n",
    "\n",
    "  def test_complaint_form(self):\n",
    "    self.assertEqual(feedback.log_customer_complaint(), 'Success')\n",
    "\n",
    "unittest.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review\n",
    "Awesome job! We’ve covered a lot of material related to unit testing in Python. We learned:\n",
    "\n",
    "The difference between manual and automated testing.\n",
    "What unit tests are.\n",
    "How to write simple tests with the assert keyword.\n",
    "How to create and run test cases with the unittest framework.\n",
    "Best practices for test fixtures, test parameterization, skipped tests and expected failures.\n",
    "The world of software testing is vast and can take time to master, but the basic principles of unit testing will almost always be applicable to any language we work with. Incorporating testing into our software is the best way to prevent unexpected bugs from occurring. The sooner we write tests, the faster we can catch and fix bugs and make our software better!\n",
    "\n",
    "### Instructions\n",
    "#### 1. The code in monitor.py adds some new functionality to the monitor in the Small World plane seats. Read through it and see what it does. Can you create some unit tests for these functions? Add your tests to tests.py, and have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import monitor\n",
    "import unittest\n",
    "\n",
    "class MonitorTests(unittest.TestCase):\n",
    "\n",
    "\n",
    "  def test_remaining_time(self):\n",
    "    expected_values = {\n",
    "      15: (0, 1),\n",
    "      500: (0, 33),\n",
    "      1000: (1, 6)\n",
    "    }\n",
    "    for key, value in expected_values.items():\n",
    "      with self.subTest(i=key):\n",
    "        self.assertEqual(monitor.calculate_remaining_time(key), value)\n",
    "\n",
    "\n",
    "  def test_customer_request(self):\n",
    "    self.assertWarns(monitor.CustomerRequestWarning, monitor.request_flight_attendant)\n",
    "\n",
    "unittest.main()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "126de395fc5ab05c9b404d5156ac230f2dc2d73638f7037ba66d30fa539ce6ef"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
